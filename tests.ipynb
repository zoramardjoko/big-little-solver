{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Our Models #\n",
    "\n",
    "We will test the stability of the solutions returned by each model by running 100 randomly generated tests for each model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biglittlematcher import BigLittleMatcher\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be our general function for testing stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stability(generator_func, build_model=None, num_tests=100):\n",
    "    stable_count = 0\n",
    "    unstable_count = 0\n",
    "    \n",
    "    for _ in range(num_tests):\n",
    "        if build_model:\n",
    "            bigs, littles, big_prefs, little_prefs, model_builder = generator_func(build_model)\n",
    "        else:\n",
    "            bigs, littles, big_prefs, little_prefs, model_builder = generator_func()\n",
    "        \n",
    "        try:\n",
    "            matcher = BigLittleMatcher(bigs, littles, big_prefs, little_prefs)\n",
    "            model_builder(matcher)\n",
    "            matches, _ = matcher.solve()\n",
    "            instabilities = matcher.check_instabilities(matches)\n",
    "            \n",
    "            if len(instabilities) == 0:\n",
    "                stable_count += 1\n",
    "            else:\n",
    "                unstable_count += 1\n",
    "        except Exception as e:\n",
    "            unstable_count += 1\n",
    "    \n",
    "    return stable_count, unstable_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will test all the models with the standard stable marriage problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sm_test(build_model_func=\"build_model\"):\n",
    "    size = random.randint(3, 6)\n",
    "    bigs = {f\"B{i}\": {} for i in range(1, size+1)}\n",
    "    littles = {f\"L{i}\": {} for i in range(1, size+1)}\n",
    "    \n",
    "    big_prefs = {}\n",
    "    little_prefs = {}\n",
    "    \n",
    "    # Choose format based on which build model we're using\n",
    "    for b in bigs:\n",
    "        if build_model_func == \"build_model\":\n",
    "            big_prefs[b] = random.sample(list(littles.keys()), len(littles))\n",
    "        else:\n",
    "            littles_list = random.sample(list(littles.keys()), len(littles))\n",
    "            big_prefs[b] = {littles_list[i]: i+1 for i in range(len(littles_list))}\n",
    "\n",
    "    for l in littles:\n",
    "        if build_model_func == \"build_model\":\n",
    "            little_prefs[l] = random.sample(list(bigs.keys()), len(bigs))\n",
    "        else:\n",
    "            bigs_list = random.sample(list(bigs.keys()), len(bigs))\n",
    "            little_prefs[l] = {bigs_list[i]: i+1 for i in range(len(bigs_list))}\n",
    "    \n",
    "    model_builder = None\n",
    "    if build_model_func == \"build_model\":\n",
    "        model_builder = lambda m: m.build_model()\n",
    "    elif build_model_func == \"build_model_smt\":\n",
    "        model_builder = lambda m: m.build_model_smt()\n",
    "    elif build_model_func == \"build_model_smti\":\n",
    "        model_builder = lambda m: m.build_model_smti()\n",
    "    \n",
    "    return bigs, littles, big_prefs, little_prefs, model_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Matching (Original) Test Results ###\n",
    "\n",
    "The results here look good because all models should be able to solve the standard matching problem. Since SMT and SMTI are both supersets of the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Standard Stable Matching with build_model:\n",
      "Stable: 100, Unstable: 0\n",
      "Testing Standard Stable Matching with build_model_smt:\n",
      "Stable: 100, Unstable: 0\n",
      "Testing Standard Stable Matching with build_model_smti:\n",
      "Stable: 100, Unstable: 0\n"
     ]
    }
   ],
   "source": [
    "# Run 100 tests for each model type\n",
    "print(\"Testing Standard Stable Matching with build_model:\")\n",
    "sm_stable, sm_unstable = test_stability(generate_sm_test, \"build_model\")\n",
    "print(f\"Stable: {sm_stable}, Unstable: {sm_unstable}\")\n",
    "\n",
    "print(\"Testing Standard Stable Matching with build_model_smt:\")\n",
    "sm_stable2, sm_unstable2 = test_stability(generate_sm_test, \"build_model_smt\")\n",
    "print(f\"Stable: {sm_stable2}, Unstable: {sm_unstable2}\")\n",
    "\n",
    "print(\"Testing Standard Stable Matching with build_model_smti:\")\n",
    "sm_stable2, sm_unstable2 = test_stability(generate_sm_test, \"build_model_smti\")\n",
    "print(f\"Stable: {sm_stable2}, Unstable: {sm_unstable2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will test the models with the stable matching with ties problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_smt_test(build_model_func=\"build_model_smt\"):\n",
    "    size = random.randint(3, 6)\n",
    "    bigs = {f\"B{i}\": {} for i in range(1, size+1)}\n",
    "    littles = {f\"L{i}\": {} for i in range(1, size+1)}\n",
    "    \n",
    "    # Generate preferences with ties\n",
    "    big_prefs = {}\n",
    "    little_prefs = {}\n",
    "    \n",
    "    for b in bigs:\n",
    "        # Complete list but with possible ties\n",
    "        ranks = {}\n",
    "        little_list = list(littles.keys())\n",
    "        random.shuffle(little_list)\n",
    "        \n",
    "        current_rank = 1\n",
    "        for l in little_list:\n",
    "            # 30% chance of keeping the same rank (making a tie)\n",
    "            if random.random() > 0.3 and l != little_list[0]:\n",
    "                current_rank += 1\n",
    "            ranks[l] = current_rank\n",
    "        big_prefs[b] = ranks\n",
    "    \n",
    "    for l in littles:\n",
    "        ranks = {}\n",
    "        big_list = list(bigs.keys())\n",
    "        random.shuffle(big_list)\n",
    "        \n",
    "        current_rank = 1\n",
    "        for b in big_list:\n",
    "            # 30% chance of keeping the same rank (making a tie)\n",
    "            if random.random() > 0.3 and b != big_list[0]:\n",
    "                current_rank += 1\n",
    "            ranks[b] = current_rank\n",
    "        little_prefs[l] = ranks\n",
    "    \n",
    "    # Map string name to actual method call\n",
    "    model_builder = None\n",
    "    if build_model_func == \"build_model_smt\":\n",
    "        model_builder = lambda m: m.build_model_smt()\n",
    "    elif build_model_func == \"build_model_smti\":\n",
    "        model_builder = lambda m: m.build_model_smti()\n",
    "    \n",
    "    return bigs, littles, big_prefs, little_prefs, model_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Matching with Ties Test Results ###\n",
    "\n",
    "The results here look good because SMT and SMTI both solve the stable matching with ties problem. This additionally looks good because SMTI is a superset of SMT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Stable Matching with Ties using build_model_smt:\n",
      "Stable: 100, Unstable: 0\n",
      "\n",
      "Testing Stable Matching with Ties using build_model_smti:\n",
      "Stable: 100, Unstable: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nTesting Stable Matching with Ties using build_model_smt:\")\n",
    "smt_stable, smt_unstable = test_stability(generate_smt_test, \"build_model_smt\")\n",
    "print(f\"Stable: {smt_stable}, Unstable: {smt_unstable}\")\n",
    "\n",
    "print(\"\\nTesting Stable Matching with Ties using build_model_smti:\")\n",
    "smt_stable2, smt_unstable2 = test_stability(generate_smt_test, \"build_model_smti\")\n",
    "print(f\"Stable: {smt_stable2}, Unstable: {smt_unstable2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will test the models with the stable matching with ties and incomplete lists problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_smti_test():\n",
    "    \"\"\"Generate a Stable Marriage with Ties and Incomplete Lists test case\"\"\"\n",
    "    size = random.randint(3, 6)\n",
    "    bigs = {f\"B{i}\": {} for i in range(1, size+1)}\n",
    "    littles = {f\"L{i}\": {} for i in range(1, size+1)}\n",
    "    \n",
    "    # Generate preferences with ties and incomplete lists\n",
    "    big_prefs = {}\n",
    "    little_prefs = {}\n",
    "    \n",
    "    for b in bigs:\n",
    "        # Each big ranks a random subset of littles\n",
    "        num_to_rank = random.randint(1, len(littles))\n",
    "        selected_littles = random.sample(list(littles.keys()), num_to_rank)\n",
    "        \n",
    "        ranks = {}\n",
    "        current_rank = 1\n",
    "        for l in selected_littles:\n",
    "            # 30% chance of keeping the same rank (making a tie)\n",
    "            if random.random() > 0.3 and l != selected_littles[0]:\n",
    "                current_rank += 1\n",
    "            ranks[l] = current_rank\n",
    "        big_prefs[b] = ranks\n",
    "    \n",
    "    for l in littles:\n",
    "        # Each little ranks a random subset of bigs\n",
    "        num_to_rank = random.randint(1, len(bigs))\n",
    "        selected_bigs = random.sample(list(bigs.keys()), num_to_rank)\n",
    "        \n",
    "        ranks = {}\n",
    "        current_rank = 1\n",
    "        for b in selected_bigs:\n",
    "            # 30% chance of keeping the same rank (making a tie)\n",
    "            if random.random() > 0.3 and b != selected_bigs[0]:\n",
    "                current_rank += 1\n",
    "            ranks[b] = current_rank\n",
    "        little_prefs[l] = ranks\n",
    "    \n",
    "    return bigs, littles, big_prefs, little_prefs, lambda m: m.build_model_smti()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Matching with Ties and Incomplete Lists Test Results ###\n",
    "\n",
    "The results here look good because SMTI solver solves the stable matching with ties and incomplete lists problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Stable Matching with Ties and Incomplete Lists:\n",
      "Stable: 100, Unstable: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTesting Stable Matching with Ties and Incomplete Lists:\")\n",
    "smti_stable, smti_unstable = test_stability(generate_smti_test)\n",
    "print(f\"Stable: {smti_stable}, Unstable: {smti_unstable}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cis1921-TLowzgGA-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
